{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b428c1",
   "metadata": {
    "id": "73b428c1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2ebbc6",
   "metadata": {
    "id": "3f2ebbc6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from optuna.exceptions import ExperimentalWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ExperimentalWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95754d27",
   "metadata": {
    "id": "95754d27",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "from replay.utils.session_handler import get_spark_session, State\n",
    "\n",
    "from replay.models import UCB, Wilson, RandomRec, LinUCB, ThompsonSampling\n",
    "from replay.experimental.scenarios.movielens_wrapper.replay_offline import OBPOfflinePolicyLearner\n",
    "from replay.experimental.scenarios.movielens_wrapper.dataset import MovielensBanditDataset\n",
    "from replay.experimental.scenarios.movielens_wrapper.utils import get_est_rewards_by_reg, bandit_subset\n",
    "from replay.utils.spark_utils import convert2spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e42a85f",
   "metadata": {
    "id": "9e42a85f",
    "outputId": "60b7eed8-18ef-4706-e880-3526779241e0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/29 19:09:30 WARN Utils: Your hostname, hdilab-hdilabALIEN05 resolves to a loopback address: 127.0.1.1; using 172.21.136.110 instead (on interface enp3s0)\n",
      "24/09/29 19:09:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/hdilab/sudakovcom/.conda/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/29 19:09:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/29 19:09:31 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "spark = State(get_spark_session()).session\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324b7d5b",
   "metadata": {
    "id": "324b7d5b"
   },
   "source": [
    "Lets define OpenBanditDataset class with random policy. For the purpose of demonstration we won't use the whole dataset but only subset of size 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca63994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rs_datasets import MovieLens\n",
    "\n",
    "data = MovieLens(\"1m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890579f",
   "metadata": {},
   "source": [
    "Оставим только 300 самых популярных айтемов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "309e0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = data.ratings\n",
    "logs['cnt'] = 1\n",
    "logs = logs[['item_id', 'cnt']].groupby(by=[\"item_id\"]).sum()\n",
    "logs = logs.sort_values(by=['cnt'], ascending=False).reset_index()\n",
    "popular_items = logs.iloc[:2000]['item_id'].tolist()\n",
    "# popular_items = logs['item_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "331c924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размер датасета логов после выброса непопулярных айтемов: (940319, 5)\n"
     ]
    }
   ],
   "source": [
    "data.ratings = data.ratings[data.ratings['item_id'].isin(popular_items)]\n",
    "print('размер датасета логов после выброса непопулярных айтемов:', data.ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002f77e",
   "metadata": {},
   "source": [
    "Оставим информацию только о фичах юзеров и айтемов которые остались в логах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adcbd325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040, 5), (2000, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.items = data.items[data.items['item_id'].isin(popular_items)]\n",
    "users = set(data.ratings['user_id'].tolist())\n",
    "data.users = data.users[data.users['user_id'].isin(users)]\n",
    "data.users.shape, data.items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986319cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29-Sep-24 19:09:35, replay, INFO: Columns with ids of users or items are present in mapping. The dataframe will be treated as an interactions log.\n",
      "INFO:replay:Columns with ids of users or items are present in mapping. The dataframe will be treated as an interactions log.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29-Sep-24 19:09:41, replay, INFO: Column with ids of users or items is absent in mapping. The dataframe will be treated as a users'/items' features dataframe.\n",
      "INFO:replay:Column with ids of users or items is absent in mapping. The dataframe will be treated as a users'/items' features dataframe.\n",
      "29-Sep-24 19:09:42, replay, INFO: Column with ids of users or items is absent in mapping. The dataframe will be treated as a users'/items' features dataframe.\n",
      "INFO:replay:Column with ids of users or items is absent in mapping. The dataframe will be treated as a users'/items' features dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model\n"
     ]
    }
   ],
   "source": [
    "dataset = MovielensBanditDataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149409e3",
   "metadata": {},
   "source": [
    "# Metrics evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6c5df26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neg: 0\n",
      "momory usage: 17.4\n",
      "658220\n",
      "282099\n",
      "Lin_ucb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:28<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hr@1': 0.009347079198833994, 'mrr@1': 0.009347079198833994, 'ndcg@1': 0.009347079198833994, 'cov@1': 0.039}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:26<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hr@3': 0.022829145535135865, 'mrr@3': 0.015079720525246955, 'ndcg@3': 0.01706114501797765, 'cov@3': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:26<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hr@10': 0.05864560369522633, 'mrr@10': 0.020825676081260278, 'ndcg@10': 0.029541098804730718, 'cov@10': 0.133}\n",
      "n_neg: 250\n",
      "momory usage: 27.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 658220/658220 [01:27<00:00, 7549.98it/s]\n",
      "100%|██████████| 4850/4850 [00:00<00:00, 9867.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870720\n",
      "282099\n",
      "Lin_ucb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:25<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hr@1': 0.009724712552693028, 'mrr@1': 0.009724712552693028, 'ndcg@1': 0.009724712552693028, 'cov@1': 0.035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:25<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hr@3': 0.023478137629548014, 'mrr@3': 0.015569564245626914, 'ndcg@3': 0.01759154992987357, 'cov@3': 0.064}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:25<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hr@10': 0.05972741177988948, 'mrr@10': 0.02131052531862714, 'ndcg@10': 0.03014992100027711, 'cov@10': 0.132}\n"
     ]
    }
   ],
   "source": [
    "n_negatives = [0, 50, 100, 150, 200, 250, 300, 350, 400]\n",
    "\n",
    "\n",
    "print('LinUCB')\n",
    "for n_neg in n_negatives:\n",
    "    print('n_neg:', n_neg)\n",
    "    print('momory usage:', psutil.virtual_memory().percent)\n",
    "    bandit_feedback_train, bandit_feedback_test = dataset.obtain_batch_bandit_feedback(test_size=0.3, is_timeseries_split=True, n_neg=n_neg)\n",
    "        \n",
    "    model_2 = LinUCB(eps = -10.0, alpha = 1.0, regr_type = 'disjoint')\n",
    "    learner_2 = OBPOfflinePolicyLearner(n_actions=dataset.n_actions,\n",
    "                                        replay_model=model_2)\n",
    "    learner_2.fit(bandit_feedback_train)\n",
    "    \n",
    "    print(learner_2.predict_and_evaluate_new(bandit_feedback_test, 1))\n",
    "    print(learner_2.predict_and_evaluate_new(bandit_feedback_test, 3))\n",
    "    print(learner_2.predict_and_evaluate_new(bandit_feedback_test, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b51d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('momory usage:', psutil.virtual_memory().percent)\n",
    "bandit_feedback_train, bandit_feedback_test = dataset.obtain_batch_bandit_feedback(test_size=0.3, is_timeseries_split=True)\n",
    "\n",
    "    \n",
    "print('UCB')\n",
    "model_1 = UCB(exploration_coef = 0.01, sample = True, seed = 123)\n",
    "learner_1 = OBPOfflinePolicyLearner(n_actions=dataset.n_actions,\n",
    "                                    replay_model=model_1)\n",
    "learner_1.fit(bandit_feedback_train)\n",
    "\n",
    "print(learner_1.predict_and_evaluate_new(bandit_feedback_test, 1))\n",
    "print(learner_1.predict_and_evaluate_new(bandit_feedback_test, 3))\n",
    "print(learner_1.predict_and_evaluate_new(bandit_feedback_test, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbcfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random')\n",
    "model_3 = RandomRec(seed=42)\n",
    "learner_3 = OBPOfflinePolicyLearner(n_actions=dataset.n_actions,\n",
    "                                    replay_model=model_3)\n",
    "learner_3.fit(bandit_feedback_train)\n",
    "\n",
    "print(learner_3.predict_and_evaluate_new(bandit_feedback_test, 1))\n",
    "print(learner_3.predict_and_evaluate_new(bandit_feedback_test, 3))\n",
    "print(learner_3.predict_and_evaluate_new(bandit_feedback_test, 10))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
